# -*- coding: utf-8 -*-
"""Iris_codsoft.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/manikantachowdary9/CODSOFT/blob/main/Iris_codsoft.ipynb
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt # for data visualization
import seaborn as sns # for statistical data visualization
# %matplotlib inline
import warnings

warnings.filterwarnings('ignore')
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt # for data visualization
import seaborn as sns # for statistical data visualization
# %matplotlib inline
import warnings

warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/codsoft/IRIS.csv')
print(df.shape)
df.head()

df.columns

# check distribution of target_class column
df['species'].value_counts()

df.info()

df.isnull().sum()

round(df.describe(),2)

sns.pairplot(df, hue='species', markers=['o', 's', 'D'])
plt.show()

plt.figure(figsize=(15,15))


plt.subplot(4, 2, 1)
fig = df.boxplot(column='sepal_length')
fig.set_title('')
fig.set_ylabel('sepal_length')


plt.subplot(4, 2, 2)
fig = df.boxplot(column='sepal_width')
fig.set_title('')
fig.set_ylabel('sepal_width')


plt.subplot(4, 2, 3)
fig = df.boxplot(column='petal_length')
fig.set_title('')
fig.set_ylabel('petal_length')


plt.subplot(4, 2, 4)
fig = df.boxplot(column='petal_width')
fig.set_title('')
fig.set_ylabel('petal_width')

plt.figure(figsize=(24,20))


plt.subplot(4, 2, 1)
fig = df['sepal_length'].hist(bins=10)
fig.set_xlabel('IP Mean')



plt.subplot(4, 2, 2)
fig = df['sepal_width'].hist(bins=10)
fig.set_xlabel('sepal_width')



plt.subplot(4, 2, 3)
fig = df['petal_length'].hist(bins=10)
fig.set_xlabel('petal_length')



plt.subplot(4, 2, 4)
fig = df['petal_width'].hist(bins=10)
fig.set_xlabel('petal_width')

X = df.drop(['species'], axis=1)

y = df['species']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 10)
X_train.shape, X_test.shape

cols = X_train.columns
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

X_train = scaler.fit_transform(X_train)

X_test = scaler.transform(X_test)
X_train = pd.DataFrame(X_train, columns=[cols])
X_test = pd.DataFrame(X_test, columns=[cols])
X_train.head()

from sklearn.svm import SVC

# import metrics to compute accuracy
from sklearn.metrics import accuracy_score

# instantiate classifier with default hyperparameters
svc=SVC()

# fit classifier to training set
svc.fit(X_train,y_train)

# make predictions on test set
y_pred=svc.predict(X_test)

# compute and print accuracy score
print('Model accuracy score with default hyperparameters: {0:0.2f}'. format(accuracy_score(y_test, y_pred)))

y_pred_train = svc.predict(X_train)

y_pred_train

print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred)

print('Confusion matrix\n\n', cm)

print('\nTrue Positives(TP) = ', cm[0,0])

print('\nTrue Negatives(TN) = ', cm[1,1])

print('\nFalse Positives(FP) = ', cm[0,1])

print('\nFalse Negatives(FN) = ', cm[1,0])

sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu')

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred))

TP = cm[0,0]
TN = cm[1,1]
FP = cm[0,1]
FN = cm[1,0]
# print classification accuracy

classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)

print('Classification accuracy : {0:0.3f}'.format(classification_accuracy))

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score


kfold=KFold(n_splits=5, shuffle=True, random_state=0)


linear_svc=SVC()


linear_scores = cross_val_score(linear_svc, X, y, cv=kfold)
# print cross-validation scores with linear kernel

print('cross-validation scores with linear kernel:\n\n{}'.format(linear_scores))
print('mean cross-validation scores with linear kernel:\n\n{}'.format(linear_scores.mean()))